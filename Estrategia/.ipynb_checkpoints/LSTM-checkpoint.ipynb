{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e839816-91a0-451b-a324-4b7ddc698d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "# Loading the model\n",
    "import tensorflow.keras\n",
    "plt.style.use(\"seaborn\")\n",
    "import pickle\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ccaddd5e-317c-4432-b2db-0892a919166f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.regularizers import l1, l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "543c46f9-7c5a-47a7-aeac-b70d478cd1d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/axel/miniforge3/envs/env_tensorflow/lib/python3.9/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "def set_seeds(seed = 100):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    \n",
    "def cw(df):\n",
    "    c0, c1 = np.bincount(df[\"dir\"])\n",
    "    w0 = (1/c0) * (len(df)) / 2\n",
    "    w1 = (1/c1) * (len(df)) / 2\n",
    "    return {0:w0, 1:w1}\n",
    "\n",
    "optimizer = Adam(lr = 0.0001)\n",
    "\n",
    "def create_model(hl = 2, hu = 100, dropout = False, rate = 0.3, regularize = False,\n",
    "                 reg = l1(0.0005), optimizer = optimizer, input_dim = 8):\n",
    "#input_dim\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=50,return_sequences=True,input_shape=(8,1)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units=50))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(units=1))\n",
    "    model.compile(optimizer='adam',loss='mean_squared_error')\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "7f22f36f-f2b4-44ed-ad60-42b552d24f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ML_Backtester():\n",
    "    ''' Class for the vectorized backtesting of (levered) Futures MAchine Learning powered trading strategies .\n",
    "    \n",
    "    Attributes\n",
    "    ============\n",
    "    filepath: str\n",
    "        local filepath of the dataset (csv-file)\n",
    "    symbol: str\n",
    "        ticker symbol (instrument) to be backtested\n",
    "    start: str\n",
    "        start date for data import\n",
    "    end: str\n",
    "        end date for data import\n",
    "    tc: float\n",
    "        proportional trading costs per trade\n",
    "    granulity: str\n",
    "        granulity 5m, 15m, 30m, 1h, 4h\n",
    "    \n",
    "    \n",
    "    Methods\n",
    "    =======\n",
    "    get_data:\n",
    "        imports the data.\n",
    "        \n",
    "    test_strategy:\n",
    "        prepares the data and backtests the trading strategy incl. reporting (wrapper).\n",
    "        \n",
    "    prepare_data:\n",
    "        prepares the data for backtesting.\n",
    "    \n",
    "    run_backtest:\n",
    "        runs the strategy backtest.\n",
    "        \n",
    "    plot_results:\n",
    "        plots the cumulative performance of the trading strategy compared to buy-and-hold.\n",
    "        \n",
    "    optimize_strategy:\n",
    "        backtests strategy for different parameter values incl. optimization and reporting (wrapper).\n",
    "    \n",
    "    find_best_strategy:\n",
    "        finds the optimal strategy (global maximum).\n",
    "        \n",
    "    add_sessions:\n",
    "        adds/labels trading sessions and their compound returns.\n",
    "        \n",
    "    add_leverage:\n",
    "        adds leverage to the strategy.\n",
    "        \n",
    "    print_performance:\n",
    "        calculates and prints various performance metrics.\n",
    "        \n",
    "    '''    \n",
    "    \n",
    "    def __init__(self, filepath, symbol, tc, granulity, window, lags, hini, hfin):\n",
    "        \n",
    "        self.filepath = filepath\n",
    "        self.symbol = symbol\n",
    "        self.tc = tc\n",
    "        self.results = None\n",
    "        self.get_data()\n",
    "        self.tp_year = (self.data.Close.count() / ((self.data.index[-1] - self.data.index[0]).days / 365.25))\n",
    "        self.granulity=granulity\n",
    "        self.window=window\n",
    "        self.lags=lags\n",
    "        self.hini=hini\n",
    "        self.hfin=hfin\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return \"Futures_Backtester(window= {}, lag = {})\".format(self.window, self.lags)\n",
    "        \n",
    "    def get_data(self):\n",
    "        ''' Imports the data.\n",
    "        '''\n",
    "        try:\n",
    "            data = pd.read_csv(\"../Data/{}/consolidado{}.csv\".format(granulity, granulity))\n",
    "        except IOError:\n",
    "            \n",
    "            path = r\"../Data/{}\".format(granulity) # use your path\n",
    "            all_files = glob.glob(path + \"/*.csv\")\n",
    "\n",
    "            out_file = \"../Data/{}/consolidado{}.csv\".format(granulity, granulity) \n",
    "            first_file = True # needed to write the header only for first file \n",
    "            for fp in all_files: \n",
    "                df = pd.read_csv(fp) \n",
    "                df = df.dropna() # remove records with blanks \n",
    "                if first_file:  \n",
    "                    df.to_csv(out_file, index=False) \n",
    "                    first_file = False \n",
    "                else: \n",
    "                    df.to_csv(out_file, index=False, header=False, mode='a') \n",
    "\n",
    "            data = pd.read_csv(\"../Data/{}/consolidado{}.csv\".format(granulity, granulity))\n",
    "        finally:  \n",
    "            data.columns = [\"Open Time\", \"Open\", \"High\", \"Low\", \"Close\",\n",
    "                  \"Volume\", \"Clos Time\", \"Quote Asset Volume\", \n",
    "                  \"Number of Trades\", \"Taker Buy Base Asset Volume\",\n",
    "                  \"Taker Buy Quote Asset Volume\", \"Ignore\" ]\n",
    "\n",
    "            data[\"Open Time\"] = pd.to_numeric(data[\"Open Time\"], errors = \"coerce\")\n",
    "            data[\"Date\"] = pd.to_datetime(data.iloc[:,0], unit = \"ms\")\n",
    "            data=data.dropna()\n",
    "            data.set_index(\"Date\", inplace = True)\n",
    "            data=data.sort_values(\"Date\", ascending=True)\n",
    "            symbol = 'Close'\n",
    "            data[\"returns\"] = np.log(data['Close'] / data['Close'].shift())\n",
    "           \n",
    "            self.data = data\n",
    "\n",
    "    \n",
    "    def test_strategy(self):\n",
    "        '''\n",
    "        Prepares the data and backtests the trading strategy incl. reporting (Wrapper).\n",
    "         \n",
    "        Parameters\n",
    "        ============\n",
    "        '''\n",
    "        self.prepare_data()\n",
    "        self.run_backtest()\n",
    "        \n",
    "        data = self.results.copy()\n",
    "        data[\"creturns\"] = data[\"returns\"].cumsum().apply(np.exp)\n",
    "        data[\"cstrategy\"] = data[\"strategy\"].cumsum().apply(np.exp)\n",
    "        self.results = data\n",
    "        self.print_performance()\n",
    "    \n",
    "    def prepare_data(self):\n",
    "        ''' Prepares the Data for Backtesting.\n",
    "        '''\n",
    "       # window = 50 now defined as init class attribute\n",
    "       # lags = 10 now defined as init class attribute\n",
    "        cols = []\n",
    "        features = [\"dir\", \"sma\", \"boll\", \"min\", \"max\", \"mom\", \"vol\"]\n",
    "        \n",
    "        df = self.data.copy()\n",
    "        df[\"dir\"] = np.where(df[\"returns\"] > 0, 1, 0)\n",
    "        df[\"sma\"] = df[symbol].rolling(window).mean() - df[symbol].rolling(150).mean()\n",
    "        df[\"boll\"] = (df[symbol] - df[symbol].rolling(window).mean()) / df[symbol].rolling(window).std()\n",
    "        df[\"min\"] = df[symbol].rolling(window).min() / df[symbol] - 1\n",
    "        df[\"max\"] = df[symbol].rolling(window).max() / df[symbol] - 1\n",
    "        df[\"mom\"] = df[\"returns\"].rolling(3).mean()\n",
    "        df[\"vol\"] = df[\"Volume\"]\n",
    "        df.dropna(inplace = True)\n",
    "        \n",
    "        cols = []\n",
    "        features = [\"Close\", \"sma\", \"boll\", \"min\", \"max\", \"mom\", \"vol\", \"dir\"]\n",
    "        cols=features\n",
    "        df.dropna(inplace = True)\n",
    "        ########################## Strategy-Specific #############################\n",
    "        split = int(len(df)*0.7)\n",
    "        train = df.iloc[:split].copy()\n",
    "        test = df.iloc[split:].copy()\n",
    "        mu, std = train.mean(), train.std() # train set parameters (mu, std) for standardization\n",
    "        train_s = (train - mu) / std \n",
    "        set_seeds(100)\n",
    "        try:\n",
    "            model = tensorflow.keras.models.load_model(\"./Models/{}/DNN_BTCUSDT_{}_W{}_L{}\".format(granulity, granulity, window, lags))\n",
    "            # Loading mu and std\n",
    "            params = pickle.load(open(\"./Models/{}/DNN_BTCUSDT_{}_W{}_L{}/params.pkl\".format(granulity, granulity, window, lags), \"rb\"))\n",
    "            mu = params[\"mu\"]\n",
    "            std = params[\"std\"]\n",
    "        except IOError:\n",
    "\n",
    "            model = create_model(hl = 3, hu = 50, dropout = True, input_dim = len(cols))\n",
    "            model.fit(x = train_s[cols], y = train[\"dir\"], epochs = 5, verbose = 0, validation_split = 0.2, shuffle = False, class_weight = cw(train))\n",
    "            #pred = model.predict(train_s[cols])\n",
    "            model.save(\"./Models/{}/DNN_BTCUSDT_{}_W{}_L{}\".format(granulity, granulity, window, lags))\n",
    "            params = {\"mu\":mu, \"std\":std}\n",
    "            pickle.dump(params, open(\"./Models/{}/DNN_BTCUSDT_{}_W{}_L{}/params.pkl\".format(granulity, granulity, window, lags), \"wb\"))\n",
    "            \n",
    "        ##########################################################################\n",
    "        \n",
    "        finally:\n",
    "            test_s = (test - mu) / std # standardization of test set features (with train set parameters!!!)\n",
    "            pred = model.predict(test_s[cols])\n",
    "            test[\"proba\"] = model.predict(test_s[cols])\n",
    "            test[\"position\"] = np.where(test.proba < 0.47, -1, np.nan) # 1. short where proba < 0.47\n",
    "            test[\"position\"] = np.where(test.proba > 0.53, 1, test.position) # 2. long where proba > 0.53\n",
    "            test.index = test.index.tz_localize(\"UTC\")\n",
    "            test[\"NYTime\"] = test.index.tz_convert(\"America/New_York\")\n",
    "            test[\"hour\"] = test.NYTime.dt.hour\n",
    "            test[\"position\"] = np.where(~test.hour.between(self.hini, self.hfin), 0, test.position) # 3. neutral in non-busy hours\n",
    "            test[\"position\"] = test.position.ffill().fillna(0) # 4. in all other cases: hold position\n",
    "\n",
    "        \n",
    "        self.results = test\n",
    "    \n",
    "    def run_backtest(self):\n",
    "        ''' Runs the strategy backtest.\n",
    "        '''\n",
    "        test=self.results.copy()\n",
    "        test[\"strategy\"] = test[\"position\"] * test[\"returns\"]\n",
    "        test[\"creturns\"] = test[\"returns\"].cumsum().apply(np.exp)\n",
    "        test[\"cstrategy\"] = test[\"strategy\"].cumsum().apply(np.exp)\n",
    "        test[\"trades\"] = test.position.diff().abs()\n",
    "        test[\"strategy_net\"] = test.strategy - test.trades * tc\n",
    "        test[\"cstrategy_net\"] = test[\"strategy_net\"].cumsum().apply(np.exp)\n",
    "        self.results=test\n",
    "    \n",
    "    def plot_results(self, leverage = False): #Adj!\n",
    "        '''  Plots the cumulative performance of the trading strategy compared to buy-and-hold.\n",
    "        '''\n",
    "        if self.results is None:\n",
    "            print(\"Run test_strategy() first.\")\n",
    "        elif leverage: # NEW!\n",
    "            title = \"{} | TC = {} | Leverage = {}\".format(self.symbol, self.tc, self.leverage)\n",
    "            self.results[[\"creturns\", \"cstrategy\", \"cstrategy_levered\"]].plot(title=title, figsize=(12, 8))\n",
    "        else:\n",
    "            title = \"{} | TC = {}\".format(self.symbol, self.tc)\n",
    "            self.results[[\"creturns\", \"cstrategy\"]].plot(title=title, figsize=(12, 8))\n",
    "            \n",
    "            \n",
    "    def optimize_strategy(self, SMA_S_range, SMA_M_range, SMA_L_range, metric = \"Multiple\"):\n",
    "        '''\n",
    "        Backtests strategy for different parameter values incl. Optimization and Reporting (Wrapper).\n",
    "         \n",
    "        Parameters\n",
    "        ============\n",
    "        SMA_S_range: tuple\n",
    "            tuples of the form (start, end, step size).\n",
    "        \n",
    "        SMA_M_range: tuple\n",
    "            tuples of the form (start, end, step size).\n",
    "            \n",
    "        SMA_L_range: tuple\n",
    "            tuples of the form (start, end, step size).\n",
    "        \n",
    "        metric: str\n",
    "            performance metric to be optimized (can be \"Multiple\" or \"Sharpe\")\n",
    "        '''\n",
    "        \n",
    "        self.metric = metric\n",
    "        \n",
    "        if metric == \"Multiple\":\n",
    "            performance_function = self.calculate_multiple\n",
    "        elif metric == \"Sharpe\":\n",
    "            performance_function = self.calculate_sharpe\n",
    "        \n",
    "        SMA_S_range = range(*SMA_S_range)\n",
    "        SMA_M_range = range(*SMA_M_range)\n",
    "        SMA_L_range = range(*SMA_L_range)\n",
    "        \n",
    "        combinations = list(product(SMA_S_range, SMA_M_range, SMA_L_range))\n",
    "         \n",
    "        performance = []\n",
    "        for comb in combinations:\n",
    "            self.prepare_data(smas = comb)\n",
    "            self.run_backtest()\n",
    "            performance.append(performance_function(self.results.strategy))\n",
    "    \n",
    "        self.results_overview =  pd.DataFrame(data = np.array(combinations), columns = [\"SMA_S\", \"SMA_M\", \"SMA_L\"])\n",
    "        self.results_overview[\"performance\"] = performance\n",
    "        self.find_best_strategy()\n",
    "        \n",
    "        \n",
    "    def find_best_strategy(self):\n",
    "        ''' Finds the optimal strategy (global maximum).\n",
    "        '''\n",
    "        \n",
    "        best = self.results_overview.nlargest(1, \"performance\")\n",
    "        SMA_S = best.SMA_S.iloc[0]\n",
    "        SMA_M = best.SMA_M.iloc[0]\n",
    "        SMA_L = best.SMA_L.iloc[0]\n",
    "        perf = best.performance.iloc[0]\n",
    "        print(\"SMA_S: {} | SMA_M: {} | SMA_L : {} | {}: {}\".format(SMA_S, SMA_M, SMA_L, self.metric, round(perf, 5)))  \n",
    "        self.test_strategy(smas = (SMA_S, SMA_M, SMA_L))\n",
    "        \n",
    "    \n",
    "    def add_sessions(self, visualize = False): # NEW!!!\n",
    "        ''' \n",
    "        Adds/Labels Trading Sessions and their compound returns.\n",
    "        \n",
    "        Parameter\n",
    "        ============\n",
    "        visualize: bool, default False\n",
    "            if True, visualize compound session returns over time\n",
    "        '''\n",
    "        \n",
    "        if self.results is None:\n",
    "            print(\"Run test_strategy() first.\")\n",
    "            \n",
    "        data = self.results.copy()\n",
    "        data[\"session\"] = np.sign(data.trades).cumsum().shift().fillna(0)\n",
    "        data[\"session_compound\"] = data.groupby(\"session\").strategy.cumsum().apply(np.exp) - 1\n",
    "        self.results = data\n",
    "        if visualize:\n",
    "            data[\"session_compound\"].plot(figsize = (12, 8))\n",
    "            plt.show()  \n",
    "        \n",
    "    def add_leverage(self, leverage, report = True): # NEW!!!\n",
    "        ''' \n",
    "        Adds Leverage to the Strategy.\n",
    "        \n",
    "        Parameter\n",
    "        ============\n",
    "        leverage: float (positive)\n",
    "            degree of leverage.\n",
    "        \n",
    "        report: bool, default True\n",
    "            if True, print Performance Report incl. Leverage.\n",
    "        '''\n",
    "        self.add_sessions()\n",
    "        self.leverage = leverage\n",
    "        \n",
    "        data = self.results.copy()\n",
    "        data[\"simple_ret\"] = np.exp(data.strategy) - 1\n",
    "        data[\"eff_lev\"] = leverage * (1 + data.session_compound) / (1 + data.session_compound * leverage)\n",
    "        data.eff_lev.fillna(leverage, inplace = True)\n",
    "        data.loc[data.trades !=0, \"eff_lev\"] = leverage\n",
    "        levered_returns = data.eff_lev.shift() * data.simple_ret\n",
    "        levered_returns = np.where(levered_returns < -1, -1, levered_returns)\n",
    "        data[\"strategy_levered\"] = levered_returns\n",
    "        data[\"cstrategy_levered\"] = data.strategy_levered.add(1).cumprod()\n",
    "        \n",
    "        self.results = data\n",
    "            \n",
    "        if report:\n",
    "            self.print_performance(leverage = True)\n",
    "            \n",
    "    ############################## Performance ######################################\n",
    "    \n",
    "    def print_performance(self, leverage = False): # Adj\n",
    "        ''' Calculates and prints various Performance Metrics.\n",
    "        '''\n",
    "        \n",
    "        data = self.results.copy()\n",
    "        \n",
    "        if leverage: # NEW!\n",
    "            to_analyze = np.log(data.strategy_levered.add(1))\n",
    "        else: \n",
    "            to_analyze = data.strategy\n",
    "            \n",
    "            \n",
    "        strategy_multiple = round(self.calculate_multiple(to_analyze), 6)\n",
    "        bh_multiple =       round(self.calculate_multiple(data.returns), 6)\n",
    "        outperf =           round(strategy_multiple - bh_multiple, 6)\n",
    "        cagr =              round(self.calculate_cagr(to_analyze), 6)\n",
    "        ann_mean =          round(self.calculate_annualized_mean(to_analyze), 6)\n",
    "        ann_std =           round(self.calculate_annualized_std(to_analyze), 6)\n",
    "        sharpe =            round(self.calculate_sharpe(to_analyze), 6)\n",
    "       \n",
    "        print(100 * \"=\")\n",
    "        print(\"BTC USDT ML STRATEGY - {}\".format(granulity))\n",
    "        print(100 * \"-\")\n",
    "        print(\"PERFORMANCE MEASURES:\")\n",
    "        print(\"\\n\")\n",
    "        print(\"Multiple (Strategy):         {}\".format(strategy_multiple))\n",
    "        print(\"Multiple (Buy-and-Hold):     {}\".format(bh_multiple))\n",
    "        print(38 * \"-\")\n",
    "        print(\"Out-/Underperformance:       {}\".format(outperf))\n",
    "        print(\"\\n\")\n",
    "        print(\"CAGR:                        {}\".format(cagr))\n",
    "        print(\"Annualized Mean:             {}\".format(ann_mean))\n",
    "        print(\"Annualized Std:              {}\".format(ann_std))\n",
    "        print(\"Sharpe Ratio:                {}\".format(sharpe))\n",
    "        \n",
    "        print(100 * \"=\")\n",
    "        \n",
    "        \n",
    "    def massive_strategy(self,granulity, l1, l2, w1, w2):\n",
    "        for lag in range(l1, l2):\n",
    "            for w in range(w1, w2):\n",
    "                granulity=granulity\n",
    "                filepath = \"../Data/{}\".format(granulity)\n",
    "                symbol = \"Close\"\n",
    "                tc = -0.0005\n",
    "                window=w\n",
    "                lags=lag\n",
    "                hini=2\n",
    "                hfin=12\n",
    "                tester = ML_Backtester(filepath = filepath, symbol = symbol,\n",
    "                                     tc = tc, granulity=granulity, window=window, lags=lags, hini=hini, hfin=hfin)\n",
    "                tester.test_strategy()\n",
    "    \n",
    "    def calculate_multiple(self, series):\n",
    "        return np.exp(series.sum())\n",
    "    \n",
    "    def calculate_cagr(self, series):\n",
    "        return np.exp(series.sum())**(1/((series.index[-1] - series.index[0]).days / 365.25)) - 1\n",
    "    \n",
    "    def calculate_annualized_mean(self, series):\n",
    "        return series.mean() * self.tp_year\n",
    "    \n",
    "    def calculate_annualized_std(self, series):\n",
    "        return series.std() * np.sqrt(self.tp_year)\n",
    "    \n",
    "    def calculate_sharpe(self, series):\n",
    "        if series.std() == 0:\n",
    "            return np.nan\n",
    "        else:\n",
    "            return self.calculate_cagr(series) / self.calculate_annualized_std(series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "da9c7961-b27f-4aec-8922-c2b758768582",
   "metadata": {},
   "outputs": [],
   "source": [
    "granulity=\"15m\"\n",
    "filepath = \"../Data/{}\".format(granulity)\n",
    "symbol = \"Close\"\n",
    "tc = -0.0005\n",
    "window=50\n",
    "lags=7\n",
    "hini=2\n",
    "hfin=12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "70ddeeec-8cee-4580-997e-c97c264039e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tester = ML_Backtester(filepath = filepath, symbol = symbol,\n",
    "tc = tc, granulity=granulity, window=window, lags=lags, hini=hini, hfin=hfin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "fcfe0139-c3f7-4c8d-840a-85853627d67b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_49 (LSTM)              (None, 8, 50)             10400     \n",
      "                                                                 \n",
      " dropout_50 (Dropout)        (None, 8, 50)             0         \n",
      "                                                                 \n",
      " lstm_50 (LSTM)              (None, 50)                20200     \n",
      "                                                                 \n",
      " dropout_51 (Dropout)        (None, 50)                0         \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 30,651\n",
      "Trainable params: 30,651\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_49_layer_call_fn, lstm_cell_49_layer_call_and_return_conditional_losses, lstm_cell_50_layer_call_fn, lstm_cell_50_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./Models/15m/DNN_BTCUSDT_15m_W50_L7/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./Models/15m/DNN_BTCUSDT_15m_W50_L7/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x2c0e38550> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x2bd497d30> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "BTC USDT ML STRATEGY - 15m\n",
      "----------------------------------------------------------------------------------------------------\n",
      "PERFORMANCE MEASURES:\n",
      "\n",
      "\n",
      "Multiple (Strategy):         147646958544.31378\n",
      "Multiple (Buy-and-Hold):     1.238548\n",
      "--------------------------------------\n",
      "Out-/Underperformance:       147646958543.07523\n",
      "\n",
      "\n",
      "CAGR:                        1.9331609358729133e+17\n",
      "Annualized Mean:             39.762665\n",
      "Annualized Std:              0.413424\n",
      "Sharpe Ratio:                4.675975567444626e+17\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "tester.test_strategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889ec3a1-09c2-44cc-bfcb-e65a60fd57bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f73c90-f46c-4e80-80fd-cef764eae325",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2015c8e3-4f6b-41e5-8ebe-06bff1d61791",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
